# [Sequence Models](https://www.coursera.org/learn/nlp-sequence-models) (NLP)

Rustam_ZðŸš€ | 20 December 2020

## References:
- [RNN Notes](https://github.com/mbadry1/DeepLearning.ai-Summary)

- Difference between RNN, LSTM, GRU: https://stats.stackexchange.com/questions/222584/difference-between-feedback-rnn-and-lstm-gru

## Contents:
- [WEEK 1](#WEEK-1)
    - Recurrent Neural Networks (forward prop, BP)

    - Gated Recurrent Unit (GRU) 

    - Long Short Term Memory (LSTM)

    - Bidirectional RNN (remebers before-after)

    - Deep RNNs

- [WEEK 2](#WEEK-2)

- [WEEK 3](#WEEK-3)

## WEEK 1
    - Recurrent Neural Networks 
    - LSTMs, GRUs, Bidirectional RNNs
Applications: speech recognition, musics generation, machine traslation, name entity recognition...

### Notation
- The text of words is represented as the vector of words
- <img src="img/01.PNG" width=500><img src="img/02.PNG" width=500>

### Recurrent Neural Network Model
- <img src="img/03.PNG" width=500><img src="img/04.PNG" width=500>
- <img src="img/05.PNG" width=500><img src="img/06.PNG" width=500>

### Backpropagation through time
- <img src="img/07.png" width=500>

### Different types of RNNs
- <img src="img/08.PNG" width=500><img src="img/09.PNG" width=500>
- <img src="img/10.PNG" width=500><img src="img/11.PNG" width=500>

### Language model and sequence generation
- <img src="img/12.PNG" width=500> 

### Gated Recurrent Unit (GRU)
- <img src="img/13.PNG" width=500><img src="img/14.PNG" width=500><img src="img/15.PNG" width=500>

### Long Short Term Memory (LSTM)
<img src="img/17.PNG" width=500><img src="img/16.png" width=500><img src="img/18.PNG" width=500>

## WEEK 2

## WEEK 3